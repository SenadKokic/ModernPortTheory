{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.special import betainc, beta\n",
    "import scipy\n",
    "from random import seed\n",
    "from numpy import dot, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_g(N, mu, sigma):\n",
    "    p1 = dot(ones(N), dot(inv(sigma), mu))\n",
    "    p2 = dot(ones(N), dot(inv(sigma), ones(N)))\n",
    "    return p1/p2\n",
    "\n",
    "def w_g(N, sigma):\n",
    "    p1 = (dot(inv(sigma), ones(N)))\n",
    "    p2 = (dot(ones(N), dot(inv(sigma), ones(N))))\n",
    "    return p1/p2\n",
    "\n",
    "def w_z(N, mu, sigma):\n",
    "    mug = mu_g(N, mu, sigma)\n",
    "    br = mu - ones(N)*mug\n",
    "    return dot(inv(sigma), br)\n",
    "\n",
    "def w_star(N, mu, sigma, gamma):\n",
    "    return w_g(N, sigma) + (1/gamma)*w_z(N, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_sq(N, mu, sigma):\n",
    "    mug = mu_g(N, mu, sigma)\n",
    "    br = mu - ones(N)*mug\n",
    "    return dot(br, dot(inv(sigma), br))\n",
    "\n",
    "def psi_asq(N, h, mu, sigma):\n",
    "    psq = psi_sq(N, mu, sigma)\n",
    "    p1 = ((h - N - 1)*psq - (N - 1))/h\n",
    "    n1 = psq**((N-1)/2)\n",
    "    n2 = (1 + psq)**(-(h-2)/2)\n",
    "    a = (N - 1)/2 ; b = (h - N + 1)/2\n",
    "    x = psq/(1+psq)\n",
    "    b = beta(a, b)*betainc(a,b,x)\n",
    "    p2 = (2*n1*n2)/(h*b)\n",
    "    return p1 + p2\n",
    "\n",
    "def k_func(N, h):\n",
    "    return ((h - N)*(h - N - 3))/(h*(h-2))\n",
    "\n",
    "def w_qt(N, h, mu, sigma, gamma):\n",
    "    k = k_func(N, h)\n",
    "    pasq = psi_asq(N, h, mu, sigma)\n",
    "    c1 = k*pasq; c2 = pasq + (N - 1)/h\n",
    "    ct = c1/c2\n",
    "    wg = w_g(N, sigma) ; wz = w_z(N, mu, sigma)\n",
    "    return wg + (ct/gamma)*wz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementable rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim_perf(\n",
    "        returns_data: pd.DataFrame,\n",
    "        h: int,\n",
    "        gamma: int\n",
    "):\n",
    "    # column names for forthcoming dataframe\n",
    "    cols = [\"t\",\n",
    "            \"Implementable\",\n",
    "            \"Plug-in\"\n",
    "            ]\n",
    "    # set blank lists for returns\n",
    "    rets = []\n",
    "    track = 0\n",
    "    for t in range(h, len(returns_data)):\n",
    "        # select which part of the file is being used for the weight calculation\n",
    "        est = returns_data[track:t - 1]\n",
    "        # filter out assets with at least 120 NaNs in the estimation window\n",
    "        valid_assets = est.columns[est.isna().sum() < h]\n",
    "        est = est[valid_assets]\n",
    "        N_temp = len(valid_assets)\n",
    "        # determine which line is being used to calculate returns\n",
    "        time_t_data = returns_data.loc[t, valid_assets].values\n",
    "        # set mu and sigma estimates\n",
    "        mu_hat = est.mean()\n",
    "        sigma_hat = est.cov()\n",
    "        # calculate all of the portfolios\n",
    "        w_imp_opt = w_qt(N_temp, h, mu_hat, sigma_hat, gamma)\n",
    "        w_pt = w_star(N_temp, mu_hat, sigma_hat, gamma)\n",
    "        row = []; row.append(t)\n",
    "        port_list = [w_imp_opt, w_pt]\n",
    "        for portfolio in port_list:\n",
    "            # calculate the returns on the data\n",
    "            row.append(dot(portfolio, time_t_data))\n",
    "        rets.append(row)\n",
    "    return pd.DataFrame(rets, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimal and naive rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sim_perf_alt(\n",
    "        returns_data: pd.DataFrame,\n",
    "        gamma: int\n",
    "):\n",
    "    # set the number of assets\n",
    "    N = len(returns_data.columns)\n",
    "    # column names for forthcoming dataframe\n",
    "    cols = [\"t\", \"Optimal\", \"Naive\"]\n",
    "    # set blank lists for returns\n",
    "    rets = []\n",
    "    # take the true mean and covariance (i.e. over entire history)\n",
    "    tmean = returns_data.mean()\n",
    "    tsigma = returns_data.cov()\n",
    "    # calculate the optimal portfolios\n",
    "    w_opt = w_star(N, tmean, tsigma, gamma)\n",
    "    \n",
    "    for t in range(len(returns_data)):\n",
    "        # determine which line is being used to calculate returns\n",
    "        time_t_data = returns_data.iloc[t]\n",
    "        \n",
    "        # Filter out assets with NaNs in the current row\n",
    "        valid_assets = time_t_data.dropna().index\n",
    "        time_t_data = time_t_data[valid_assets].values\n",
    "        \n",
    "        # Calculate the returns for w_opt and w_naive for each row\n",
    "        valid_asset_indices = [returns_data.columns.get_loc(asset) for asset in valid_assets]\n",
    "        w_opt_valid = w_opt[valid_asset_indices]  # Filter w_opt for valid assets\n",
    "        w_naive_valid = np.ones(len(valid_assets)) / len(valid_assets)  # Naive weights already adjusted for valid assets\n",
    "        row = [t]\n",
    "        row.append(np.dot(w_opt_valid, time_t_data))  # Return for optimal portfolio\n",
    "        row.append(np.dot(w_naive_valid, time_t_data))  # Return for naive portfolio\n",
    "        rets.append(row)\n",
    "    return pd.DataFrame(rets, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sharpe(mu, sigma):\n",
    "    # just return the ratio\n",
    "    return mu/sigma\n",
    "\n",
    "def find_cer(mu, sigma, gamma):\n",
    "    # return the certainty equivalent return\n",
    "    return mu - (gamma/2)*sigma**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, only a few of the files have missing values. They are handled accordingly.\n",
    "\n",
    "(Sourced from Ken French's website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv with the 5 portfolio data\n",
    "fiveinddata = pd.read_csv(\"/Users/senadkokic/Desktop/MRP/Data/5_industry.csv\", sep = \"\\t\")\n",
    "# rename the first column\n",
    "fiveinddata = fiveinddata.rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "# consider column 2 onwards\n",
    "fiveinddata = fiveinddata[fiveinddata.columns[1:]]\n",
    "\n",
    "# read in the csv with the 10 portfolio data\n",
    "tenmomdata = pd.read_csv(\"/Users/senadkokic/Desktop/MRP/Data/10_Momentum_Portfolios_Monthly.csv\", sep = \"\\t\")\n",
    "# rename the first column\n",
    "tenmomdata = tenmomdata.rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "tenmomdata = tenmomdata[tenmomdata.columns[1:]]\n",
    "\n",
    "# read in the csv with the 25 portfolio data\n",
    "fama_tt_data = pd.read_csv(\"/Users/senadkokic/Desktop/MRP/Data/25_Size_Book_To_Market_Adj.csv\", sep = \"\\t\")\n",
    "# rename the first column\n",
    "fama_tt_data = fama_tt_data.rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "# consider columns 2 onwards\n",
    "fama_tt_data = fama_tt_data[fama_tt_data.columns[1:]]\n",
    "fama_tt_data.replace(-99.99, np.nan, inplace=True)\n",
    "\n",
    "# load the 32 data\n",
    "thrtwo_dat = pd.read_csv(\"/Users/senadkokic/Desktop/MRP/Data/32_op.csv\",sep = \"\\t\")\n",
    "# rename the first column\n",
    "thrtwo_dat = thrtwo_dat.rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "# consider columns 2 onwards\n",
    "thrtwo_dat = thrtwo_dat[thrtwo_dat.columns[1:]]\n",
    "\n",
    "# read in the csv with the 100 portfolio data\n",
    "fornine = pd.read_csv(\"/Users/senadkokic/Desktop/MRP/Data/49.csv\", sep = \"\\t\")\n",
    "# rename the first column\n",
    "fornine = fornine.rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "# consider column 2 onwards\n",
    "fornine = fornine[fornine.columns[1:]]\n",
    "fornine.replace(-99.99, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32324)\n",
    "l = [\"fiveinddata\", \"tenmomdata\", \"fama_tt_data\",\"thrtwo_dat\",\"fornine\"]\n",
    "q = 0\n",
    "for dataset in [fiveinddata, tenmomdata, fama_tt_data,thrtwo_dat,fornine]:\n",
    "    dataset=dataset/100\n",
    "    res = calc_sim_perf(dataset, h = 120, gamma = 3)\n",
    "    means = res.mean()[1:] ; sds = res.std()[1:]\n",
    "    #print(\"Dataset:\", l[q], \"\\n\", round(find_cer(means, sds, gamma = 3),4))\n",
    "    print(\"Dataset:\", l[q], \"\\n\", round(find_sharpe(means, sds), 4))\n",
    "    q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"fiveinddata\", \"tenmomdata\", \"fama_tt_data\",\"thrtwo_dat\",\"fornine\"]\n",
    "q = 0\n",
    "for dataset in [fiveinddata, tenmomdata, fama_tt_data,thrtwo_dat,fornine]:\n",
    "    dataset=dataset/100\n",
    "    res = calc_sim_perf_alt(dataset, gamma = 3)\n",
    "    means = res.mean()[1:] ; sds = res.std()[1:]\n",
    "    #print(\"Dataset:\", l[q], \"\\n\", round(find_cer(means, sds, gamma = 3),4))\n",
    "    print(\"Dataset:\", l[q], \"\\n\", round(find_sharpe(means, sds), 4))\n",
    "    q += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
